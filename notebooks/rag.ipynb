{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-05T11:42:49.824094Z",
     "start_time": "2025-05-05T11:42:48.910430Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in c:\\users\\aiden\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (0.3.25)\n",
      "Requirement already satisfied: langchain_community in c:\\users\\aiden\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (0.3.25)\n",
      "Requirement already satisfied: sentence-transformers in c:\\users\\aiden\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (4.1.0)\n",
      "Requirement already satisfied: faiss-cpu in c:\\users\\aiden\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (1.11.0)\n",
      "Requirement already satisfied: transformers in c:\\users\\aiden\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (4.43.4)\n",
      "Requirement already satisfied: torch in c:\\users\\aiden\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (2.6.0+cu118)\n",
      "Requirement already satisfied: accelerate in c:\\users\\aiden\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (0.33.0)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.58 in c:\\users\\aiden\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain) (0.3.65)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in c:\\users\\aiden\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain) (0.3.8)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.17 in c:\\users\\aiden\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain) (0.3.45)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\users\\aiden\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain) (2.11.4)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\aiden\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain) (2.0.28)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\aiden\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain) (2.32.3)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\aiden\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain) (6.0.2)\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in c:\\users\\aiden\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain) (4.0.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in c:\\users\\aiden\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.58->langchain) (9.1.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\aiden\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.58->langchain) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in c:\\users\\aiden\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.58->langchain) (24.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in c:\\users\\aiden\\appdata\\roaming\\python\\python310\\site-packages (from langchain-core<1.0.0,>=0.3.58->langchain) (4.13.2)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\aiden\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.58->langchain) (3.0.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\aiden\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langsmith<0.4,>=0.1.17->langchain) (0.28.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\aiden\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langsmith<0.4,>=0.1.17->langchain) (3.10.18)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\users\\aiden\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in c:\\users\\aiden\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langsmith<0.4,>=0.1.17->langchain) (0.23.0)\n",
      "Requirement already satisfied: anyio in c:\\users\\aiden\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (3.7.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\aiden\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (2022.12.7)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\aiden\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.0.9)\n",
      "Requirement already satisfied: idna in c:\\users\\aiden\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (3.4)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\aiden\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\aiden\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\aiden\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\aiden\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\aiden\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3,>=2->langchain) (3.1.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\aiden\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3,>=2->langchain) (1.26.20)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\aiden\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\aiden\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain_community) (3.8.4)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in c:\\users\\aiden\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain_community) (0.6.7)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in c:\\users\\aiden\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain_community) (2.9.1)\n",
      "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in c:\\users\\aiden\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain_community) (0.4.0)\n",
      "Collecting numpy>=1.26.2 (from langchain_community)\n",
      "  Using cached numpy-2.2.6-cp310-cp310-win_amd64.whl.metadata (60 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\aiden\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (22.2.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\aiden\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\aiden\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.8.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\aiden\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.3.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\aiden\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.3.1)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\aiden\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (3.26.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in c:\\users\\aiden\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (0.9.0)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in c:\\users\\aiden\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain_community) (1.0.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\aiden\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community) (1.0.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\aiden\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from sentence-transformers) (4.67.1)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\aiden\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from sentence-transformers) (1.6.1)\n",
      "Requirement already satisfied: scipy in c:\\users\\aiden\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from sentence-transformers) (1.9.3)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in c:\\users\\aiden\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from sentence-transformers) (0.24.5)\n",
      "Requirement already satisfied: Pillow in c:\\users\\aiden\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from sentence-transformers) (10.0.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\aiden\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (3.18.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\aiden\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (2023.3.22)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\aiden\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (0.4.4)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in c:\\users\\aiden\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (0.19.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\aiden\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2023.10.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\aiden\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\aiden\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\aiden\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\aiden\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "  Using cached numpy-1.26.4-cp310-cp310-win_amd64.whl.metadata (61 kB)\n",
      "Requirement already satisfied: psutil in c:\\users\\aiden\\appdata\\roaming\\python\\python310\\site-packages (from accelerate) (7.0.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\aiden\\appdata\\roaming\\python\\python310\\site-packages (from tqdm->sentence-transformers) (0.4.6)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\aiden\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.3.0)\n",
      "Requirement already satisfied: exceptiongroup in c:\\users\\aiden\\appdata\\roaming\\python\\python310\\site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.2.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\aiden\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from jinja2->torch) (2.1.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\aiden\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scikit-learn->sentence-transformers) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\aiden\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scikit-learn->sentence-transformers) (3.1.0)\n",
      "INFO: pip is looking at multiple versions of scipy to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting scipy (from sentence-transformers)\n",
      "  Downloading scipy-1.15.3-cp310-cp310-win_amd64.whl.metadata (60 kB)\n",
      "Using cached numpy-1.26.4-cp310-cp310-win_amd64.whl (15.8 MB)\n",
      "Downloading scipy-1.15.3-cp310-cp310-win_amd64.whl (41.3 MB)\n",
      "   ---------------------------------------- 0.0/41.3 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/41.3 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/41.3 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.3/41.3 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.3/41.3 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.5/41.3 MB 728.2 kB/s eta 0:00:56\n",
      "    --------------------------------------- 0.8/41.3 MB 905.5 kB/s eta 0:00:45\n",
      "   - -------------------------------------- 1.6/41.3 MB 1.4 MB/s eta 0:00:28\n",
      "   - -------------------------------------- 1.6/41.3 MB 1.4 MB/s eta 0:00:28\n",
      "   - -------------------------------------- 1.8/41.3 MB 1.3 MB/s eta 0:00:31\n",
      "   -- ------------------------------------- 2.1/41.3 MB 1.2 MB/s eta 0:00:32\n",
      "   -- ------------------------------------- 2.4/41.3 MB 1.2 MB/s eta 0:00:32\n",
      "   -- ------------------------------------- 2.6/41.3 MB 1.2 MB/s eta 0:00:31\n",
      "   --- ------------------------------------ 3.1/41.3 MB 1.3 MB/s eta 0:00:30\n",
      "   --- ------------------------------------ 3.7/41.3 MB 1.4 MB/s eta 0:00:27\n",
      "   ---- ----------------------------------- 4.5/41.3 MB 1.6 MB/s eta 0:00:24\n",
      "   ----- ---------------------------------- 5.2/41.3 MB 1.8 MB/s eta 0:00:21\n",
      "   ----- ---------------------------------- 6.0/41.3 MB 1.9 MB/s eta 0:00:19\n",
      "   ------ --------------------------------- 7.1/41.3 MB 2.1 MB/s eta 0:00:17\n",
      "   ------- -------------------------------- 7.9/41.3 MB 2.2 MB/s eta 0:00:16\n",
      "   -------- ------------------------------- 8.7/41.3 MB 2.3 MB/s eta 0:00:15\n",
      "   --------- ------------------------------ 9.4/41.3 MB 2.4 MB/s eta 0:00:14\n",
      "   ---------- ----------------------------- 10.5/41.3 MB 2.5 MB/s eta 0:00:13\n",
      "   ----------- ---------------------------- 11.5/41.3 MB 2.6 MB/s eta 0:00:12\n",
      "   ----------- ---------------------------- 12.3/41.3 MB 2.7 MB/s eta 0:00:11\n",
      "   ------------ --------------------------- 13.4/41.3 MB 2.8 MB/s eta 0:00:11\n",
      "   ------------- -------------------------- 13.9/41.3 MB 2.8 MB/s eta 0:00:10\n",
      "   ------------- -------------------------- 14.2/41.3 MB 2.7 MB/s eta 0:00:10\n",
      "   -------------- ------------------------- 14.9/41.3 MB 2.7 MB/s eta 0:00:10\n",
      "   --------------- ------------------------ 16.0/41.3 MB 2.8 MB/s eta 0:00:09\n",
      "   ---------------- ----------------------- 17.3/41.3 MB 2.9 MB/s eta 0:00:09\n",
      "   ----------------- ---------------------- 18.4/41.3 MB 3.0 MB/s eta 0:00:08\n",
      "   ------------------ --------------------- 19.1/41.3 MB 3.1 MB/s eta 0:00:08\n",
      "   ------------------- -------------------- 19.7/41.3 MB 3.1 MB/s eta 0:00:08\n",
      "   ------------------- -------------------- 20.4/41.3 MB 3.0 MB/s eta 0:00:07\n",
      "   -------------------- ------------------- 21.5/41.3 MB 3.1 MB/s eta 0:00:07\n",
      "   --------------------- ------------------ 22.5/41.3 MB 3.1 MB/s eta 0:00:06\n",
      "   ---------------------- ----------------- 23.1/41.3 MB 3.1 MB/s eta 0:00:06\n",
      "   ---------------------- ----------------- 23.1/41.3 MB 3.1 MB/s eta 0:00:06\n",
      "   ---------------------- ----------------- 23.3/41.3 MB 3.0 MB/s eta 0:00:06\n",
      "   ---------------------- ----------------- 23.6/41.3 MB 3.0 MB/s eta 0:00:06\n",
      "   ----------------------- ---------------- 24.1/41.3 MB 2.9 MB/s eta 0:00:06\n",
      "   ----------------------- ---------------- 24.6/41.3 MB 2.9 MB/s eta 0:00:06\n",
      "   ------------------------ --------------- 25.2/41.3 MB 2.9 MB/s eta 0:00:06\n",
      "   ------------------------ --------------- 25.4/41.3 MB 2.9 MB/s eta 0:00:06\n",
      "   ------------------------- -------------- 26.2/41.3 MB 2.9 MB/s eta 0:00:06\n",
      "   -------------------------- ------------- 27.3/41.3 MB 2.9 MB/s eta 0:00:05\n",
      "   --------------------------- ------------ 28.3/41.3 MB 3.0 MB/s eta 0:00:05\n",
      "   ---------------------------- ----------- 29.6/41.3 MB 3.0 MB/s eta 0:00:04\n",
      "   ----------------------------- ---------- 30.7/41.3 MB 3.1 MB/s eta 0:00:04\n",
      "   ------------------------------- -------- 32.0/41.3 MB 3.1 MB/s eta 0:00:03\n",
      "   -------------------------------- ------- 33.0/41.3 MB 3.2 MB/s eta 0:00:03\n",
      "   --------------------------------- ------ 34.1/41.3 MB 3.2 MB/s eta 0:00:03\n",
      "   --------------------------------- ------ 34.9/41.3 MB 3.2 MB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 35.9/41.3 MB 3.3 MB/s eta 0:00:02\n",
      "   ----------------------------------- ---- 37.0/41.3 MB 3.3 MB/s eta 0:00:02\n",
      "   ------------------------------------ --- 38.0/41.3 MB 3.3 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 38.8/41.3 MB 3.3 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 39.6/41.3 MB 3.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  40.9/41.3 MB 3.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 41.3/41.3 MB 3.4 MB/s eta 0:00:00\n",
      "Installing collected packages: numpy, scipy\n",
      "\n",
      "  Attempting uninstall: numpy\n",
      "\n",
      "    Found existing installation: numpy 1.23.0\n",
      "\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "    Uninstalling numpy-1.23.0:\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "      Successfully uninstalled numpy-1.23.0\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "  Attempting uninstall: scipy\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "    Found existing installation: scipy 1.9.3\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "    Uninstalling scipy-1.9.3:\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "      Successfully uninstalled scipy-1.9.3\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   -------------------- ------------------- 1/2 [scipy]\n",
      "   ---------------------------------------- 2/2 [scipy]\n",
      "\n",
      "Successfully installed numpy-1.26.4 scipy-1.15.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Error parsing dependencies of pyser: Expected matching RIGHT_PARENTHESIS for LEFT_PARENTHESIS, after version specifier\n",
      "    sphinx-rtd-theme (>=0.1.10b0S) ; extra == 'doc'\n",
      "                     ~~~~~~~~~~~^\n",
      "WARNING: Error parsing dependencies of simple-youtube-api: Expected matching RIGHT_PARENTHESIS for LEFT_PARENTHESIS, after version specifier\n",
      "    sphinx-rtd-theme (>=0.1.10b0S) ; extra == 'doc'\n",
      "                     ~~~~~~~~~~~^\n",
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\aiden\\AppData\\Local\\Programs\\Python\\Python310\\Lib\\site-packages\\~.mpy'.\n",
      "  You can safely remove it manually.\n",
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\aiden\\AppData\\Local\\Programs\\Python\\Python310\\Lib\\site-packages\\~cipy.libs'.\n",
      "  You can safely remove it manually.\n",
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\aiden\\AppData\\Local\\Programs\\Python\\Python310\\Lib\\site-packages\\~cipy'.\n",
      "  You can safely remove it manually.\n",
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "deepsort 0.0.5 requires scikit_learn==1.1.3, but you have scikit-learn 1.6.1 which is incompatible.\n",
      "deepsort 0.0.5 requires scipy==1.9.3, but you have scipy 1.15.3 which is incompatible.\n",
      "numba 0.56.4 requires numpy<1.24,>=1.18, but you have numpy 1.26.4 which is incompatible.\n",
      "openai-whisper 20230314 requires tiktoken==0.3.1, but you have tiktoken 0.3.3 which is incompatible.\n",
      "p5 0.8.4 requires Pillow==9.0.1, but you have pillow 10.0.1 which is incompatible.\n",
      "pyannote-database 5.1.0 requires typer>=0.12.1, but you have typer 0.7.0 which is incompatible.\n",
      "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain langchain_community sentence-transformers faiss-cpu transformers torch accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a33ab62bf679f364",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-07T01:56:05.176266Z",
     "start_time": "2025-05-07T01:56:00.241898Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\aiden\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\utils\\_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.embeddings import SentenceTransformerEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from transformers import pipeline\n",
    "from langchain.llms import HuggingFacePipeline\n",
    "from langchain.chains import RetrievalQA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eaf9a8318765b62c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-07T01:56:05.190270Z",
     "start_time": "2025-05-07T01:56:05.180717Z"
    }
   },
   "outputs": [],
   "source": [
    "class Config:\n",
    "    SEED: int = 42\n",
    "    SAMPLE: int = 10000\n",
    "    BASE_DATA_PATH: str = '../data/'\n",
    "    BASE_OUTPUT_PATH: str = '../output/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c3d61067c712530",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-07T01:56:08.708047Z",
     "start_time": "2025-05-07T01:56:05.193893Z"
    }
   },
   "outputs": [],
   "source": [
    "file_path = f'{Config.BASE_DATA_PATH}/arXiv_scientific dataset.csv'\n",
    "\n",
    "df = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7b6f101fcc30fc86",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-07T01:56:08.730116Z",
     "start_time": "2025-05-07T01:56:08.714263Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'title', 'category', 'category_code', 'published_date',\n",
       "       'updated_date', 'authors', 'first_author', 'summary',\n",
       "       'summary_word_count'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ece6987c654e14b8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-07T01:56:08.771281Z",
     "start_time": "2025-05-07T01:56:08.730931Z"
    }
   },
   "outputs": [],
   "source": [
    "df = df.sample(Config.SAMPLE, random_state=Config.SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3d71c07263a7e08",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-07T01:56:08.775493Z",
     "start_time": "2025-05-07T01:56:08.772562Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f235ec9806ea997a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-07T01:56:08.778796Z",
     "start_time": "2025-05-07T01:56:08.776334Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'title', 'category', 'category_code', 'published_date',\n",
       "       'updated_date', 'authors', 'first_author', 'summary',\n",
       "       'summary_word_count'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5a12018c51d4f4e8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-07T01:56:08.816450Z",
     "start_time": "2025-05-07T01:56:08.779541Z"
    }
   },
   "outputs": [],
   "source": [
    "docs = [\n",
    "    f\"\"\"title: {title}\n",
    "author: {authors}\n",
    "publish_date: {published_date}\n",
    "summary: {summary}\"\"\"\n",
    "    for title, authors, published_date, summary in zip(df[\"title\"], df[\"authors\"], df[\"published_date\"], df[\"summary\"])\n",
    "]\n",
    "\n",
    "splitter = CharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
    "texts = []\n",
    "for d in docs:\n",
    "    texts.extend(splitter.split_text(d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "38bbb28183e9a5ea",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-07T01:56:08.819627Z",
     "start_time": "2025-05-07T01:56:08.817319Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(docs)=10000\n",
      "len(texts)=10000\n"
     ]
    }
   ],
   "source": [
    "print(f'{len(docs)=}')\n",
    "print(f'{len(texts)=}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6c091a97c297544b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-07T01:56:08.823696Z",
     "start_time": "2025-05-07T01:56:08.821689Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('title: Machine Learning and the Future of Realism\\n'\n",
      " \"author: ['Giles Hooker', 'Cliff Hooker']\\n\"\n",
      " 'publish_date: 4/15/17\\n'\n",
      " 'summary: The preceding three decades have seen the emergence, rise, and '\n",
      " 'proliferation\\n'\n",
      " 'of machine learning (ML). From half-recognised beginnings in perceptrons,\\n'\n",
      " 'neural nets, and decision trees, algorithms that extract correlations (that '\n",
      " 'is,\\n'\n",
      " 'patterns) from a set of data points have broken free from their origin in\\n'\n",
      " 'computational cognition to embrace all forms of problem solving, from voice\\n'\n",
      " 'recognition to medical diagnosis to automated scientific research and\\n'\n",
      " 'driverless cars, and it is now widely opined that the real industrial\\n'\n",
      " 'revolution lies less in mobile phone and similar than in the maturation and\\n'\n",
      " 'universal application of ML. Among the consequences just might be the '\n",
      " 'triumph\\n'\n",
      " 'of anti-realism over realism.')\n"
     ]
    }
   ],
   "source": [
    "import pprint as pp\n",
    "\n",
    "pp.pprint(docs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1ea575c8ac57d905",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-07T01:56:56.651079Z",
     "start_time": "2025-05-07T01:56:08.824633Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aiden\\AppData\\Local\\Temp\\ipykernel_21152\\1965970792.py:1: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embed = SentenceTransformerEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\aiden\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "embed = SentenceTransformerEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "vectorstore = FAISS.from_texts(docs, embed)\n",
    "vectorstore.save_local(f\"{Config.BASE_OUTPUT_PATH}/faiss_index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4053d16d7e1d3db3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-07T01:56:57.291342Z",
     "start_time": "2025-05-07T01:56:56.652478Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8bdb961e7af045f9be31024e97df3b97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.40k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\aiden\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\huggingface_hub\\file_download.py:159: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\aiden\\.cache\\huggingface\\hub\\models--google--flan-t5-small. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b33d690ae2f8412583d22a0ba84f65ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/308M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bfa20eb8951b4a35a3cf3047876dc7be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5c074d9ad5048edb334d8de4a903571",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/2.54k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6de8d64986894ab794f36ece2556a203",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(…)a5b18a05535c9e14c7a355904270e15b0945ea86:   0%|          | 0.00/792k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "253528ad125d4887bac94d4e4ad91b6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/2.42M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8baa8be708748af89ede9f457ae3c2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/2.20k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aiden\\AppData\\Local\\Temp\\ipykernel_21152\\1499822159.py:6: LangChainDeprecationWarning: The class `HuggingFacePipeline` was deprecated in LangChain 0.0.37 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFacePipeline``.\n",
      "  llm = HuggingFacePipeline(pipeline=hf_pipe)\n"
     ]
    }
   ],
   "source": [
    "hf_pipe = pipeline(\n",
    "    \"text2text-generation\",\n",
    "    model=\"google/flan-t5-small\",\n",
    "    device_map=\"cpu\"  # CPU by default; or set device_map={\"\": 0} for GPU\n",
    ")\n",
    "llm = HuggingFacePipeline(pipeline=hf_pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ec81c45782edf938",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-07T01:56:57.294693Z",
     "start_time": "2025-05-07T01:56:57.292256Z"
    }
   },
   "outputs": [],
   "source": [
    "qa = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=vectorstore.as_retriever(search_kwargs={\"k\": 5}),\n",
    "    return_source_documents=True,  # <-- return docs in output\n",
    "    verbose=True,                  # <-- print chain steps (optional)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dfe082f5b193e5d9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-07T01:56:58.881629Z",
     "start_time": "2025-05-07T01:56:57.295645Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aiden\\AppData\\Local\\Temp\\ipykernel_21152\\4218667418.py:1: LangChainDeprecationWarning: The method `Chain.__call__` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  res = qa({\"query\": \"Who are author of Machine Learning and the Future of Realism?\"})\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1794 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\aiden\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\generation\\utils.py:1259: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "🏷️ Answer:\n",
      " Giles Hooker \n",
      "\n",
      "📄 Retrieved documents:\n",
      "\n",
      "----- Doc #1 -----\n",
      "{}\n",
      "title: Machine Learning and the Future of Realism\n",
      "author: ['Giles Hooker', 'Cliff Hooker']\n",
      "publish_date: 4/15/17\n",
      "summary: The preceding three decades have seen the emergence, rise, and proliferation\n",
      "of machine learning (ML). From half-recognised beginnings in perceptrons,\n",
      "neural nets, and decision trees, algorithms that extract correlations (that is,\n",
      "patterns) from a set of data points have broken free from their origin in\n",
      "computational cognition to embrace all forms of problem solving, from voice\n",
      "recognition to medical diagnosis to automated scientific research and\n",
      "driverless cars, and it is now widely opined that the real industrial\n",
      "revolution lies less in mobile phone and similar than in the maturation and\n",
      "universal application of ML. Among the consequences just might be the triumph\n",
      "of anti-realism over realism.\n",
      "\n",
      "----- Doc #2 -----\n",
      "{}\n",
      "title: The role of prior information and computational power in Machine\n",
      "  Learning\n",
      "author: ['Diego Marcondes', 'Adilson Simonis', 'Junior Barrera']\n",
      "publish_date: 10/31/22\n",
      "summary: Science consists on conceiving hypotheses, confronting them with empirical\n",
      "evidence, and keeping only hypotheses which have not yet been falsified. Under\n",
      "deductive reasoning they are conceived in view of a theory and confronted with\n",
      "empirical evidence in an attempt to falsify it, and under inductive reasoning\n",
      "they are conceived based on observation, confronted with empirical evidence and\n",
      "a theory is established based on the not falsified hypotheses. When the\n",
      "hypotheses testing can be performed with quantitative data, the confrontation\n",
      "can be achieved with Machine Learning methods, whose quality is highly\n",
      "dependent on the hypotheses' complexity, hence on the proper insertion of prior\n",
      "information into the set of hypotheses seeking to decrease its complexity\n",
      "without loosing good hypotheses. However, Machine Learning tools have been\n",
      "applied under the pragmatic view of instrumentalism, which is concerned only\n",
      "with the performance of the methods and not with the understanding of their\n",
      "behavior, leading to methods which are not fully understood. In this context,\n",
      "we discuss how prior information and computational power can be employed to\n",
      "solve a learning problem, but while prior information and a careful design of\n",
      "the hypotheses space has as advantage the interpretability of the results,\n",
      "employing high computational power has the advantage of a higher performance.\n",
      "We discuss why learning methods which combine both should work better from an\n",
      "understanding and performance perspective, arguing in favor of basic\n",
      "theoretical research on Machine Learning, in special about how properties of\n",
      "classifiers may be identified in parameters of modern learning models.\n",
      "\n",
      "----- Doc #3 -----\n",
      "{}\n",
      "title: Efficient and Robust Machine Learning for Real-World Systems\n",
      "author: ['Franz Pernkopf', 'Wolfgang Roth', 'Matthias Zoehrer', 'Lukas Pfeifenberger', 'Guenther Schindler', 'Holger Froening', 'Sebastian Tschiatschek', 'Robert Peharz', 'Matthew Mattina', 'Zoubin Ghahramani']\n",
      "publish_date: 12/5/18\n",
      "summary: While machine learning is traditionally a resource intensive task, embedded\n",
      "systems, autonomous navigation and the vision of the Internet-of-Things fuel\n",
      "the interest in resource efficient approaches. These approaches require a\n",
      "carefully chosen trade-off between performance and resource consumption in\n",
      "terms of computation and energy. On top of this, it is crucial to treat\n",
      "uncertainty in a consistent manner in all but the simplest applications of\n",
      "machine learning systems. In particular, a desideratum for any real-world\n",
      "system is to be robust in the presence of outliers and corrupted data, as well\n",
      "as being `aware' of its limits, i.e.\\ the system should maintain and provide an\n",
      "uncertainty estimate over its own predictions. These complex demands are among\n",
      "the major challenges in current machine learning research and key to ensure a\n",
      "smooth transition of machine learning technology into every day's applications.\n",
      "In this article, we provide an overview of the current state of the art of\n",
      "machine learning techniques facilitating these real-world requirements. First\n",
      "we provide a comprehensive review of resource-efficiency in deep neural\n",
      "networks with focus on techniques for model size reduction, compression and\n",
      "reduced precision. These techniques can be applied during training or as\n",
      "post-processing and are widely used to reduce both computational complexity and\n",
      "memory footprint. As most (practical) neural networks are limited in their ways\n",
      "to treat uncertainty, we contrast them with probabilistic graphical models,\n",
      "which readily serve these desiderata by means of probabilistic inference. In\n",
      "that way, we provide an extensive overview of the current state-of-the-art of\n",
      "robust and efficient machine learning for real-world systems.\n",
      "\n",
      "----- Doc #4 -----\n",
      "{}\n",
      "title: ToyArchitecture: Unsupervised Learning of Interpretable Models of the\n",
      "  World\n",
      "author: ['Jaroslav Vítků', 'Petr Dluhoš', 'Joseph Davidson', 'Matěj Nikl', 'Simon Andersson', 'Přemysl Paška', 'Jan Šinkora', 'Petr Hlubuček', 'Martin Stránský', 'Martin Hyben', 'Martin Poliak', 'Jan Feyereisl', 'Marek Rosa']\n",
      "publish_date: 3/20/19\n",
      "summary: Research in Artificial Intelligence (AI) has focused mostly on two extremes:\n",
      "either on small improvements in narrow AI domains, or on universal theoretical\n",
      "frameworks which are usually uncomputable, incompatible with theories of\n",
      "biological intelligence, or lack practical implementations. The goal of this\n",
      "work is to combine the main advantages of the two: to follow a big picture\n",
      "view, while providing a particular theory and its implementation. In contrast\n",
      "with purely theoretical approaches, the resulting architecture should be usable\n",
      "in realistic settings, but also form the core of a framework containing all the\n",
      "basic mechanisms, into which it should be easier to integrate additional\n",
      "required functionality.\n",
      "  In this paper, we present a novel, purposely simple, and interpretable\n",
      "hierarchical architecture which combines multiple different mechanisms into one\n",
      "system: unsupervised learning of a model of the world, learning the influence\n",
      "of one's own actions on the world, model-based reinforcement learning,\n",
      "hierarchical planning and plan execution, and symbolic/sub-symbolic integration\n",
      "in general. The learned model is stored in the form of hierarchical\n",
      "representations with the following properties: 1) they are increasingly more\n",
      "abstract, but can retain details when needed, and 2) they are easy to\n",
      "manipulate in their local and symbolic-like form, thus also allowing one to\n",
      "observe the learning process at each level of abstraction. On all levels of the\n",
      "system, the representation of the data can be interpreted in both a symbolic\n",
      "and a sub-symbolic manner. This enables the architecture to learn efficiently\n",
      "using sub-symbolic methods and to employ symbolic inference.\n",
      "\n",
      "----- Doc #5 -----\n",
      "{}\n",
      "title: How to avoid machine learning pitfalls: a guide for academic researchers\n",
      "author: ['Michael A. Lones']\n",
      "publish_date: 8/5/21\n",
      "summary: Mistakes in machine learning practice are commonplace, and can result in a\n",
      "loss of confidence in the findings and products of machine learning. This guide\n",
      "outlines common mistakes that occur when using machine learning, and what can\n",
      "be done to avoid them. Whilst it should be accessible to anyone with a basic\n",
      "understanding of machine learning techniques, it focuses on issues that are of\n",
      "particular concern within academic research, such as the need to do rigorous\n",
      "comparisons and reach valid conclusions. It covers five stages of the machine\n",
      "learning process: what to do before model building, how to reliably build\n",
      "models, how to robustly evaluate models, how to compare models fairly, and how\n",
      "to report results.\n"
     ]
    }
   ],
   "source": [
    "res = qa({\"query\": \"Who are author of Machine Learning and the Future of Realism?\"})\n",
    "print(\"🏷️ Answer:\\n\", res[\"result\"], \"\\n\")\n",
    "print(\"📄 Retrieved documents:\")\n",
    "for i, doc in enumerate(res[\"source_documents\"], 1):\n",
    "    # doc.page_content is the text, doc.metadata might have your CSV row info\n",
    "    print(f\"\\n----- Doc #{i} -----\")\n",
    "    print(doc.metadata)\n",
    "    print(doc.page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8dae299aee941e0b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-07T01:57:18.237565Z",
     "start_time": "2025-05-07T01:57:18.226470Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Giles Hooker'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res['result']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d806b9ff1076251c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
